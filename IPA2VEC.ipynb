{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1YqxZfD1NAhcDZGM8VS57mlr5R6aUxGgp",
      "authorship_tag": "ABX9TyMglMKvgX8lSToJZMkLHnyB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IkuStudies/abraxalexicon/blob/main/IPA2VEC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install csv\n",
        "!pip install numpy\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iplBf5Fh3BSI",
        "outputId": "a6a0f88b-f58c-40fc-d3bc-4ad052b5c3f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement csv (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for csv\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "IJR6Ngja288L",
        "outputId": "8186724e-b44e-48c6-d58c-4ba5adae171d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-4b77fa495dcf>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphoneme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m  \u001b[0;31m# Ignore additional columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mtranscription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscribe_ipa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoneme\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected at least 2, got 1)"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "ipa_mapping = {\n",
        "    'a': 1, 'ɑ': 1, 'ɐ': 1, 'æ': 2, 'ɒ': 2, 'ɓ': 3, 't͡ʃ': 4, 'ɕ': 4, 'ɖ': 5, 'ð': 5, 'ɗ': 5, 'ʣ': 6, 'ʤ': 6, 'ɛ': 7, 'ə': 7, 'ɘ': 7, 'ɚ': 7,\n",
        "    'ɛ̃': 8, 'ɛ̃ː': 8, 'ɛ̃ːʷ': 8, 'ɛ̃ːʲ': 8, 'ɛ̃ːʷʲ': 8, 'ɛ̃ʷ': 8, 'ɛ̃ʲ': 8, 'ɛ̃ʷʲ': 8, 'ɛ̃ːʷʲʰ': 8, 'ɛ̃ʷʰ': 8, 'ɛ̃ʷʲʰ': 8, 'ɛ̃ʲʰ': 8,\n",
        "    'ɛ̃ːʰ': 8, 'ɛ̃ʰ': 8, 'ɛ̃ʷʰ': 8, 'ɛ̃ʷʲʰ': 8, 'ɛː': 9, 'ɛːʷ': 9, 'ɛːʲ': 9, 'ɛːʷʲ': 9, 'ɛʷ': 9, 'ɛʲ': 9, 'ɛʷʲ': 9, 'ɛːʷʲʰ': 9,\n",
        "    'ɛʷʰ': 9, 'ɛʷʲʰ': 9, 'ɛʲʰ': 9, 'əː': 10, 'əːʷ': 10, 'əːʲ': 10, 'əːʷʲ': 10, 'əʷ': 10, 'əʲ': 10, 'əʷʲ': 10, 'əːʷʲʰ': 10, 'əʷʰ': 10,\n",
        "    'əʷʲʰ': 10, 'əʲʰ': 10, 'e': 11, 'ɘ̃': 11, 'ɘ̃ː': 11, 'ɘ̃ːʷ': 11, 'ɘ̃ːʲ': 11, 'ɘ̃ːʷʲ': 11, 'ɘ̃ʷ': 11, 'ɘ̃ʲ': 11, 'ɘ̃ʷʲ': 11, 'ɘ̃ːʷʲʰ': 11,\n",
        "    'ɘ̃ʷʰ': 11, 'ɘ̃ʷʲʰ': 11, 'ɘ̃ʲʰ': 11, 'ɘ̃ʰ': 11, 'ɘ̃ʰ': 11, 'ɘ̃ʷʰ': 11, 'ɘ̃ʷʲʰ': 11, 'ɛ̃': 12, 'ɛ̃ː': 12, 'ɛ̃ːʷ': 12, 'ɛ̃ːʲ': 12,\n",
        "    'ɛ̃ːʷʲ': 12, 'ɛ̃ʷ': 12, 'ɛ̃ʲ': 12, 'ɛ̃ʷʲ': 12, 'ɛ̃ːʷʲʰ': 12, 'ɛ̃ʷʰ': 12, 'ɛ̃ʷʲʰ': 12, 'ɛ̃ʲʰ': 12, 'ɛ̃ːʰ': 12, 'ɛ̃ʰ': 12, 'ɛ̃ʷʰ': 12,\n",
        "    'ɛ̃ʷʲʰ': 12, 'ə̃': 13, 'ə̃ː': 13, 'ə̃ːʷ': 13, 'ə̃ːʲ': 13, 'ə̃ːʷʲ': 13, 'ʷʲ': 13, 'ə̃ʷ': 13, 'ə̃ʲ': 13, 'ə̃ʷʲ': 13, 'ə̃ːʷʲʰ': 13,\n",
        "    'ə̃ʷʰ': 13, 'ə̃ʷʲʰ': 13, 'ə̃ʲʰ': 13, 'ə̃ːʰ': 13, 'ə̃ʰ': 13, 'ə̃ʷʰ': 13, 'ə̃ʷʲʰ': 13, 'ɪ': 14, 'i': 14, 'ʝ': 15, 'k': 16, 'l': 17,\n",
        "    'ɫ': 17, 'ɬ': 17, 'ɮ': 17, 'ʟ': 17, 'ɱ': 18, 'ŋ': 19, 'ɲ': 20, 'ɳ': 21, 'ɴ': 22, 'ø': 23, 'œ': 23, 'ɸ': 24, 'p': 25, 'ɹ': 26, 'ɾ': 27,\n",
        "    'r': 27, 'ɻ': 27, 'ʀ': 27, 's': 28, 'ʂ': 29, 'ʃ': 29, 'ʈ': 30, 'θ': 31, 't': 32, 'ʊ': 33, 'u': 33, 'ʋ': 34, 'ⱱ': 35, 'w': 36, 'x': 37,\n",
        "    'ɣ': 37, 'z': 38, 'ʒ': 39, 'ʐ': 40, 'ʑ': 40, 'ʔ': 41\n",
        "}\n",
        "\n",
        "\n",
        "# Function to transcribe IPA string to numerical values using ipa_mapping\n",
        "def transcribe_ipa(ipa_string):\n",
        "    ipa_transcription = []\n",
        "    for char in ipa_string:\n",
        "        if char in ipa_mapping:\n",
        "            ipa_transcription.append(ipa_mapping[char])\n",
        "    return np.array(ipa_transcription)\n",
        "\n",
        "input_file = '/content/drive/MyDrive/formatted/formatted_english.csv'\n",
        "output_file = 'english_w_IPA2VEC.csv'\n",
        "max_length = 18  # Maximum length for numerical representations\n",
        "\n",
        "# Open input and output files\n",
        "with open(input_file, 'r') as file_in, open(output_file, 'w', newline='') as file_out:\n",
        "    reader = csv.reader(file_in)\n",
        "    writer = csv.writer(file_out)\n",
        "\n",
        "    for row in reader:\n",
        "        word, phoneme, *_ = row  # Ignore additional columns\n",
        "        transcription = transcribe_ipa(phoneme)\n",
        "\n",
        "        # Truncate the transcription if the length exceeds the maximum\n",
        "        if len(transcription) > max_length:\n",
        "            transcription = transcription[:max_length]\n",
        "\n",
        "        # Pad the transcription values with zeros to match the maximum length\n",
        "        padded_transcription = np.pad(transcription, (0, max_length - len(transcription)))\n",
        "\n",
        "        # Convert the padded transcription to string format enclosed in brackets\n",
        "        padded_transcription_str = '[' + ' '.join(map(str, padded_transcription)) + ']'\n",
        "\n",
        "        output_row = [word, phoneme, padded_transcription_str]\n",
        "        writer.writerow(output_row)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def convert_json_for_milvus(json_file, output_file):\n",
        "    with open(json_file, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    \n",
        "    rows = []\n",
        "    for i, item in enumerate(data):\n",
        "        embedding_str = item[\" embedding\"]\n",
        "        embedding_list = [float(val) for val in embedding_str.strip(\"[]\").split()]\n",
        "        \n",
        "        row = {\n",
        "            \"id\": int(i),\n",
        "            \"word\": str(item[\"word\"]),\n",
        "            \" embedding\": embedding_list,\n",
        "            \" pronunciation\": str(item[\" pronunciation\"])\n",
        "        }\n",
        "        rows.append(row)\n",
        "    \n",
        "    milvus_data = {\n",
        "        \"rows\": rows\n",
        "    }\n",
        "    \n",
        "    with open(output_file, 'w') as file:\n",
        "        json.dump(milvus_data, file, indent=4, ensure_ascii=False)\n",
        "\n",
        "# Example usage\n",
        "json_file_path = '/content/turkish.json'\n",
        "output_file_path = 'turkish_milvus_formatted.json'\n",
        "\n",
        "# Convert the JSON file to the Milvus format\n",
        "convert_json_for_milvus(json_file_path, output_file_path)\n"
      ],
      "metadata": {
        "id": "kEnt0-NeaF5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import math\n",
        "\n",
        "def split_json(input_file, output_prefix, num_files):\n",
        "    with open(input_file, 'r') as input_file:\n",
        "        data = json.load(input_file)\n",
        "        total_rows = len(data[\"rows\"])\n",
        "        rows_per_file = math.ceil(total_rows / num_files)\n",
        "\n",
        "        for i in range(num_files):\n",
        "            start_index = i * rows_per_file\n",
        "            end_index = min((i + 1) * rows_per_file, total_rows)\n",
        "            subset_data = {\n",
        "                \"rows\": data[\"rows\"][start_index:end_index]\n",
        "            }\n",
        "            output_file = f\"{output_prefix}_{i}.json\"\n",
        "            with open(output_file, 'w') as output_file:\n",
        "                json.dump(subset_data, output_file, indent=4)\n",
        "\n",
        "# Example usage\n",
        "input_file_path = '/content/drive/MyDrive/boyah/german_milvus_formatted.json'\n",
        "output_prefix = 'german'\n",
        "num_files = 3\n",
        "\n",
        "# Split the JSON file into multiple files\n",
        "split_json(input_file_path, output_prefix, num_files)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sZ0MER1Qd6QM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def fix_json_field_names(json_data):\n",
        "    fixed_data = []\n",
        "    for row in json_data[\"rows\"]:\n",
        "        fixed_row = {}\n",
        "        for key, value in row.items():\n",
        "            fixed_key = key.strip()  # Remove leading/trailing spaces from the field name\n",
        "            fixed_row[fixed_key] = value\n",
        "        fixed_data.append(fixed_row)\n",
        "    json_data[\"rows\"] = fixed_data\n",
        "    return json_data\n",
        "\n",
        "# Read the JSON file with UTF-8 encoding\n",
        "with open(\"/content/drive/MyDrive/boyah/arab2_2.json\", encoding=\"utf-8\") as file:\n",
        "    json_content = json.load(file)\n",
        "\n",
        "# Fix the field names\n",
        "fixed_json = fix_json_field_names(json_content)\n",
        "\n",
        "# Write the fixed JSON to a new file with UTF-8 encoding\n",
        "with open(\"arab6.json\", \"w\", encoding=\"utf-8\") as file:\n",
        "    json.dump(fixed_json, file, indent=4, ensure_ascii=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "uBSqjZr-iDAj",
        "outputId": "a9b90c80-6245-4fbe-bb9b-8b72e652a2d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-819552cfe6df>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Write the fixed JSON to a new file with UTF-8 encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arab6.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "git clone https://github.com/zilliztech/cloud-vectordb-examples.git\n",
        "pip3 install pymilvus\n",
        "cd cloud-vectordb-examples\n",
        "cd python\n",
        "\n",
        "change this config.ini file uri = https://in01-daf1771fc27e45a.aws-us-west-2.vectordb.zillizcloud.com:19542\n",
        "user = db_admin\n",
        "password = ******\n",
        "secure = True\n",
        "python3 hello_zilliz_vectordb.py\n",
        "\n",
        "should be similarlooking to this \n",
        "Connecting to DB: https://in01-daf1771fc27e45a.aws-us-west-2.vectordb.zillizcloud.com:19542\n",
        "Success!\n",
        "Creating example collection: book\n",
        "Schema: {...}\n",
        "Success!\n",
        "Inserting 100000 entities... \n",
        "Succeed in 6.0288 seconds!\n",
        "Building AutoIndex...\n",
        "Succeed in 18.9118 seconds!\n",
        "Loading collection...\n",
        "Succeed in 2.5229 seconds!\n",
        "Searching vector:[[...][...]...]\n",
        "search 0 latency: 0.0057 seconds!\n",
        "Searching vector:[[...][...]...]\n",
        "search 1 latency: 0.0049 seconds!\n",
        "Searching vector:[[...][...]...]\n",
        "search 2 latency: 0.0051 seconds!\n",
        "...\n",
        "..."
      ],
      "metadata": {
        "id": "BXZPIqP89N4v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}