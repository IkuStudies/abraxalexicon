{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1SRONPVNl_7_OA6BN7EAuBPt-lej9AKF8",
      "authorship_tag": "ABX9TyOBZdqhq9fKALYm91zOQrXM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IkuStudies/abraxalexicon/blob/main/updatejsons1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#UPDATE EXISTING JSON FILES\n",
        "import json\n",
        "\n",
        "# IPA mapping\n",
        "ipa_mapping = {\n",
        " #VOWELS 1.x\n",
        "# A sound\n",
        "    'e': 1.1,  # b_a_ke\n",
        "    'æ': 1.15,  # c_a_t\n",
        "    'ä': 1.15,  # f_a_t\n",
        "    'ã': 1.1,\n",
        "# ahh sound\n",
        "    'ɔ': 1.2,  # t_o_p\n",
        "    'ɑ': 1.2,  # f_a_ther\n",
        "    'ɒ': 1.2,  # t_o_p\n",
        "    'a': 1.2,  # f_a_ther\n",
        "    'ʡ̆': 1.2,  # gl_o_ttal\n",
        "    'ʡ': 1.2,  # gl_o_ttal\n",
        "    'ø': 1.2,  # t_o_p\n",
        "    'ɤ̞': 1.2,  # s_o_ng\n",
        "    'ɶ': 1.2,  # t_op\n",
        "    'ɐ': 1.2,  # abo_ut\n",
        "    'á': 1.2,\n",
        "    'ʢ': 1.2,  # fr_o_g  \n",
        "    'ʕ': 1.2,  # bra_c_e\n",
        "# uhh sound\n",
        "    'ʉ': 1.3,  # u_nder\n",
        "    'ɨ': 1.3,  # r_o_ugh\n",
        "    'ʌ': 1.3,  # b_u_tter\n",
        "    'ʔ': 1.3,  # c_u_t\n",
        "    'ʔ̞': 1.3,  # b_u_tter\n",
        "    'ʊ': 1.3,  # p_ut\n",
        "# eh sound\n",
        "    'e̞': 1.4,  # b_e_t\n",
        "    'ɛ': 1.4,  # b_e_tter\n",
        "    'ɘ': 1.4,  # b_i_rd\n",
        "    'ɵ': 1.4,  # b_ird\n",
        "    'ɜ': 1.4,  # h_e_rd\n",
        "    'ɞ': 1.4,  # b_ir_d\n",
        "    'ø̞': 1.4,  # h_u_rt\n",
        "    'ɤ': 1.4,  # s_urge\n",
        "    'ɪ': 1.4,  # k_i_t\n",
        "    'ə': 1.4,  # a_bout\n",
        "# ee sound\n",
        "    'y': 1.5,  # f_ew\n",
        "    'i': 1.5,  # f_ee_t\n",
        "    'ẽ': 1.5,\n",
        "# ooh sound\n",
        "    'ɯ': 1.6,  # u_niversity  https://www.youtube.com/watch?v=_fLCg4gupUc     \n",
        "    'u': 1.6,  # f_oo_d\n",
        "    'ʏ': 1.6,  # hoo_k\n",
        "    'ũ': 1.7,\n",
        "# oh sound\n",
        "    'o̞': 1.7,  # b_o_at\n",
        "    'œ': 1.7,  # g_o_ld\n",
        "    'o': 1.7,  # g_o   \n",
        "# CONSONANTS\n",
        "#b and p 2.x\n",
        "# b\n",
        "    'b̪': 2.1,  # ta_b_le (dental)\n",
        "    'ʙ̥': 2.1,  # e_b_b (voiceless)\n",
        "    'ʙ': 2.1,  # e_b_b\n",
        "    'b': 2.1,  # b_oy\n",
        "    'ɾ̼': 2.1,  # bu_tt_er (linguolabial)\n",
        "    'ɾ̥': 2.1,  # bu_tt_er (voiceless)\n",
        "    'ɾ': 2.1,  # bu_tt_er\n",
        "    'ɓ': 2.1,\n",
        "# p\n",
        "    'p': 2.5,  # p_en\n",
        "    'p̪': 2.5,  # s_p_in (dental)\n",
        "# d and t and th 4.x\n",
        "# d\n",
        "    'd̼': 3.1,  # s_u_d_den (linguolabial)\n",
        "    'd': 3.1,  # d_ime\n",
        "    'ɖ': 3.1,  # s_u_d_den\n",
        "    'd͡': 3.1,  # d_u_ally\n",
        "    'ɗ': 3.1,\n",
        "# t\n",
        "    't': 3.5,  # t_ime\n",
        "    'ʈ': 3.5,  # s_t_rap\n",
        "    't̼': 3.5,  # s_u_t\n",
        "    't': 3.5,  # t_rap\n",
        "    't͡': 3.5,\n",
        "# th\n",
        "    'θ̼': 3.7,  # s_u_th (linguolabial)\n",
        "    'ð̼': 3.7,  # th_is (linguolabial)\n",
        "    'θ': 3.7,  # th_ink\n",
        "    'ð': 3.7,  # th_is\n",
        "    'θ̠': 3.7,  # th_in (retracted)\n",
        "    'ð̠': 3.7,  # th_en (retracted)\n",
        "# k\n",
        "    'k': 4.1,  # c_a_ke\n",
        "    'q': 4.1,  # c_o_t\n",
        "    'x': 4.1,  # lo_ch\n",
        "    'χ': 4.1,  # lo_ch (uvular)\n",
        "    'c': 4.1,  # k_e_k\n",
        "# g\n",
        "    'ɣ': 4.5,  # g_uy\n",
        "    'ɡ': 4.5,  # g_uy\n",
        "    'ɢ': 4.5,  # G_od (uvular)\n",
        "    'ɢ̆': 4.5,  # G_od\n",
        "    'g': 4.5,  # g_uy\n",
        "    'ɡ̃': 4.5,\n",
        "# fa/va\n",
        "    'ɸ': 5.1,  # f_ish\n",
        "    'β': 5.2,  # v_oice\n",
        "    'f': 5.1,  # f_ish\n",
        "    'v': 5.2,  # v_oice\n",
        "    'ⱱ̟': 5.2,  # v_alveolar\n",
        "    'ⱱ': 5.2,  # v_alveolar\n",
        "#n and m 3.x\n",
        "# n\n",
        "    'ɳ̊': 6.1,  # t_ur_n (voiceless)\n",
        "    'n̼': 6.1,  # w_i_n (linguolabial)\n",
        "    'n̥': 6.1,  # s_n_ake (voiceless)\n",
        "    'n': 6.1,  # n_ine\n",
        "    'ɳ': 6.1,  # t_ur_n (nasal)\n",
        "    'ɲ̊': 6.1,  # si_n (voiceless)\n",
        "    'ɲ': 6.1,  # si_gn\n",
        "    'ŋ̊': 6.1,  # si_ng (voiceless)\n",
        "    'ŋ': 6.1,  # si_ng\n",
        "    'ɴ': 6.1,  # si_ng\n",
        "    'ñ': 6.1,\n",
        "# m\n",
        "    'm̥': 6.5,  # s_m_ile (voiceless)\n",
        "    'm': 6.5,  # m_ine\n",
        "    'ɱ': 6.5,  # s_m_ile (nasal)\n",
        "\n",
        "# h\n",
        "    'ħ': 7.1,  # Ha\n",
        "    'ʜ': 7.1,  # h_ow\n",
        "    'h': 7.1,  # h_at\n",
        "    'ɦ': 7.1,  # h_and\n",
        "\n",
        "# w\n",
        "    'ɰ': 8.1,  # w_e\n",
        "    'w': 8.1,  # w_ood\n",
        "# y\n",
        "    'j': 9.1,  # y_e_s\n",
        "    'ɟ': 9.1,  # y_e_s (palatal) \n",
        "    'ʝ': 9.1,  # y_e_s\n",
        "    'ʄ': 9.1,\n",
        "# l\n",
        "    'ʎ̝': 9.9,  # mi_ll_ion (palatalized lateral)\n",
        "    'l': 9.9,  # l_et\n",
        "    'ɭ': 9.9,  # mi_ll_ion\n",
        "    'ʎ': 9.9,  # mi_ll_ion (palatal)\n",
        "    'ʟ': 9.9,  # be_ll\n",
        "    'ʟ̠': 9.9,  # ve_ll_um (retracted)\n",
        "    'ʎ̆': 9.9,  # mi_ll_ion (extra-short)\n",
        "    'ʟ̆': 9.9,  # be_ll (extra-short)\n",
        "# r\n",
        "    'ɹ̥': 10.1,  # b_r_ing (voiceless)\n",
        "    'ɹ̠̊˔': 10.1,  # th_r_ow (voiceless retroflex)\n",
        "    'ɹ̠˔': 10.1,  # th_r_ow (retroflex)\n",
        "    'ɻ̊˔': 10.1,  # th_r_ow (voiceless retroflex)\n",
        "    'ɻ˔': 10.1,  # th_r_ow (retroflex)\n",
        "    'r': 10.1,  # r_ed\n",
        "    'r̥': 10.1,  # r_ed (voiceless)\n",
        "    'ʀ̥': 10.1,  # r_ed (uvular voiceless)\n",
        "    'ʀ': 10.1,  # r_ed (uvular)\n",
        "    'ɺ̥': 10.1,  # flu_tt_er (voiceless)\n",
        "    'ɺ': 10.1,  # flu_tt_er\n",
        "    'ɹ': 10.1,  # r_ead\n",
        "    'ɻ': 10.1,  # r_ed\n",
        "    'ʁ': 10.1,  # r_ed\n",
        "    'ɽ̊': 10.1,  # bu_tt_er (voiceless retroflex)\n",
        "    'ɽ': 10.1,  # bu_tt_er (retroflex)\n",
        "    'ʟ̝': 10.1,  # lra\n",
        "# z\n",
        "    'z': 11.1,  # z_one\n",
        "    'ɮ': 11.1,  # z_one (voiced)\n",
        "    'ʒ': 11.1,  # mea_s_ure\n",
        "    'ʑ': 11.1,  # mea_s_ure (voiced)\n",
        "    'ʐ': 11.1,  # mea_s_ure (voiced)\n",
        "    'ʑ': 11.1,  # mea_s_ure (voiced)\n",
        "    's': 11.1,  # s_un\n",
        "# sh\n",
        "    'ʃ': 11.5,  # s_h_e\n",
        "    'ʂ': 11.5,  # s_h_ut    \n",
        "    'ɕ': 11.5,  # s_h_y\n",
        "    'ç': 11.5,  # h_atch\n",
        "    'ɬ': 11.5,  # whi_st_le\n",
        "    'ꞎ': 11.5,  # whi_st_le\n",
        "}\n",
        "\n",
        "\n",
        "import json\n",
        "\n",
        "def process_json_files(input_files):\n",
        "    for input_file in input_files:\n",
        "        with open(input_file, 'r+') as file:\n",
        "            data = json.load(file)\n",
        "            rows = data['rows']\n",
        "            for row in rows:\n",
        "                pronunciation = row['pronunciation']\n",
        "\n",
        "                # Check for doubled characters and remove one of them\n",
        "                doubled_chars = set()\n",
        "                updated_pronunciation = \"\"\n",
        "                for char in pronunciation:\n",
        "                    if char in doubled_chars:\n",
        "                        continue\n",
        "                    if char * 2 in pronunciation:\n",
        "                        doubled_chars.add(char)\n",
        "                    updated_pronunciation += char\n",
        "\n",
        "                # Remove unwanted characters from pronunciation\n",
        "                updated_pronunciation = updated_pronunciation.replace(':', '').replace('ˌ', '').replace('̩', '').replace('̯', '').replace('|', '').replace('ˤ', '').replace('ː', '').replace('_', '').replace(' ', '').replace(']', '').replace('ʼ', '').replace('ʷ', '')\n",
        "\n",
        "                # Update embedding based on the updated pronunciation\n",
        "                embedding = []\n",
        "                for char in updated_pronunciation:\n",
        "                    if char in ipa_mapping:\n",
        "                        embedding.append(ipa_mapping[char])\n",
        "\n",
        "                # Pad the embedding if it is shorter than 18\n",
        "                if len(embedding) < 18:\n",
        "                    embedding.extend([0] * (18 - len(embedding)))\n",
        "\n",
        "                # Truncate the embedding if it is longer than 18\n",
        "                if len(embedding) > 18:\n",
        "                    embedding = embedding[:18]\n",
        "\n",
        "                # Update the row's fields\n",
        "                row['embedding'] = embedding\n",
        "                row['pronunciation'] = updated_pronunciation\n",
        "\n",
        "            # Move the file pointer to the beginning and truncate the file\n",
        "            file.seek(0)\n",
        "            file.truncate()\n",
        "\n",
        "            # Write the modified data back to the file\n",
        "            json.dump(data, file, ensure_ascii=False, indent=4)\n",
        "\n",
        "        print(f\"JSON processing completed for '{input_file}'. Modified file: '{input_file}'\")\n",
        "\n",
        "input_files = ['/content/drive/MyDrive/Abraxa/fa.json', '/content/drive/MyDrive/Abraxa/fr.json', '/content/drive/MyDrive/Abraxa/ge.json', '/content/drive/MyDrive/Abraxa/ge2.json', '/content/drive/MyDrive/Abraxa/ge3.json', '/content/drive/MyDrive/Abraxa/greek.json', '/content/drive/MyDrive/Abraxa/hebrew.json']\n",
        "process_json_files(input_files)\n"
      ],
      "metadata": {
        "id": "RGEf87VUyqkG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d2a2088-fd53-4bb0-88be-5ace6ffd7da6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON processing completed for '/content/drive/MyDrive/Abraxa/fa.json'. Modified file: '/content/drive/MyDrive/Abraxa/fa.json'\n",
            "JSON processing completed for '/content/drive/MyDrive/Abraxa/fr.json'. Modified file: '/content/drive/MyDrive/Abraxa/fr.json'\n",
            "JSON processing completed for '/content/drive/MyDrive/Abraxa/ge.json'. Modified file: '/content/drive/MyDrive/Abraxa/ge.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def update_id_field(file_path, code_word):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    for entity in data['rows']:\n",
        "        entity['id'] = entity['id'].replace(entity['id'][:2], code_word)\n",
        "\n",
        "    with open(file_path, 'w', encoding='utf-8') as file:\n",
        "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
        "\n",
        "    print(f\"ID field updated. JSON file '{file_path}' modified.\")\n",
        "\n",
        "# Usage example\n",
        "input_file = '/content/drive/MyDrive/Abraxa/tk.json'\n",
        "code_word = 'turkish'\n",
        "update_id_field(input_file, code_word)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFHn2nslgWPr",
        "outputId": "d3cd5ec0-1328-433b-e008-48c7a70c0f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID field updated. JSON file '/content/drive/MyDrive/Abraxa/tk.json' modified.\n"
          ]
        }
      ]
    }
  ]
}